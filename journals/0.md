# TP-GAN: Simple Adversarial Network With Additional Player for Dense Depth Image Estimation

## Journal

IEEE Access, DOI [10.1109/ACCESS.2023.3272292](https://ieeexplore.ieee.org/document/10113647)

## Authors

ANDI HENDRA AND YASUSHI KANAZAWA, (Member, IEEE)

## Dataset

1. Indoor NYU Depth v2
    - N. Silberman, D. Hoiem, P. Kohli, and R. Fergus, ‘‘Indoor segmentation and support inference from RGBD images,’’ in Proc. Eur. Conf. Comput. Vis. (ECCV), vol. 7546, Oct. 2012, pp. 746–760.
2. Outdoor KITTI data
    - A. Geiger, P. Lenz, C. Stiller, and R. Urtasun, ‘‘Vision meets robotics: The KITTI dataset,’’ Int. J. Robot. Res., vol. 32, no. 11, pp. 1231–1237, Sep. 2013.

## Training

1. Implement adversarial depth estimation network
based on deep learning Tensorflow [37]
2. Keras framework [38]
3. The training is done on Ubuntu 16.04
4. An NVIDIA GeForce GTX 1080 GPU with 8 GB memory.
5. 50 epochs using an adaptive moment estimation (Adam) optimizer with the exception of the discriminator
6. Discriminator uses Stochastic Gradient Descent (SGD) as encouraged in the works [39].
    - A. C. Wilson, R. Roelofs, S. Mitchell, N. Srebro, and B. Recht, ‘‘The marginal value of adaptive gradient methods in machine learning,’’ in Proc. 31st Int. Conf. Neural Inf. Process. Syst., 2018, pp. 4151–4161.

## Method

1. Generative Adversarial Network (GAN)
    - I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, and Y. Bengio, ‘‘Generative adversarial nets,’’ in Proc. Adv.
Neural Inf. Process. Syst., vol. 27, 2014, pp. 1–5
2. Using conditional GAN (cGAN)
3. Three Player GAN (cGAN)
4. The first player, generator, learn to synthesize depth images
    - Earns how to create more realistic depth maps. In fact, the generator continuously seeks the output that appears plausible to the discriminator.
    - Reconfigured the residual network (ResNet) as a backbone model.
    - The generator, on the other hand, works to maximize the log of the predicted probability of discriminator for counterfeit images.
    - The generator model was not trained independently and instead had its weight updated by the loss of the discriminator.
5. The second player, discriminator, classifies the generated depth
    - Discovers how to distinguish between ground truth and synthetic depth maps.
    - Patch GAN
    - The discriminator is trained to maximize the predicted probability of real images and the inverted probability of deceptive
images throughout training.
6. The third player, refiner, enhances the final reconstructed dept
    - conv-batch-activation-dropout
    - The refiner utilizes to improve the generator result as feedback from the discriminator.
    - The refiner model is updated by the previous generator weight as well as the discriminator feedback for every input batch.
7. SSIM loss function
    - N. Silberman, D. Hoiem, P. Kohli, and R. Fergus, ‘‘Indoor segmentation and support inference from RGBD images,’’ in Proc. Eur. Conf. Comput.
    - The SSIM loss will com-
pute the perceptual difference based on the visible structure
Vis. (ECCV), vol. 7546, Oct. 2012, pp. 746–760.
8. Adversarial learning advantages to formulate the problem of learning depth from monocular inputs as an image translation problem

## Result

1. Accuracy threshold
    - δ < 1.25 = 0.819
    - δ < 1.252 = 0.960
    - δ < 1.25 = 0.989
2. Error rate
    - RMS = 0.509
    - LOG10 = 0.60
    - REL = 0.143
3. Regardless of its simple structure, the presence of the third player (TP) in adversarial learning effectively improves the overall depth prediction performance of the model.
4. Proposed model required less training time to converge compared with the aforementioned related methods regardless of the GPU device

## Shortcoming
